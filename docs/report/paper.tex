%"runningheads" enables:
%  - page number on page 2 onwards
%  - title/authors on even/odd pages
%This is good for other readers to enable proper archiving among other papers and pointing to content.
%Even if the title page states the title, when printed and stored in a folder, when blindly opening the folder, one could hit not the title page, but an arbitrary page. Therefore, it is good to have title printed on the pages, too.
\documentclass[runningheads,a4paper,11pt]{llncs}

%Even though `american`, `english` and `USenglish` are synonyms for babel package (according to https://tex.stackexchange.com/questions/12775/babel-english-american-usenglish), the llncs document class is prepared to avoid the overriding of certain names (such as "Abstract." -> "Abstract" or "Fig." -> "Figure") when using `english`, but not when using the other 2.
\usepackage[english]{babel}

%better font, similar to the default springer font
%cfr-lm is preferred over lmodern. Reasoning at http://tex.stackexchange.com/a/247543/9075
\usepackage[%
rm={oldstyle=false,proportional=true},%
sf={oldstyle=false,proportional=true},%
tt={oldstyle=false,proportional=true,variable=true},%
qt=false%
]{cfr-lm}
%
%if more space is needed, exchange cfr-lm by mathptmx
%\usepackage{mathptmx}

\usepackage{graphicx}

%extended enumerate, such as \begin{compactenum}
\usepackage{paralist}

%put figures inside a text
%\usepackage{picins}
%use
%\piccaptioninside
%\piccaption{...}
%\parpic[r]{\includegraphics ...}
%Text...

%Sorts the citations in the brackets
%\usepackage{cite}

\usepackage[T1]{fontenc}

%for demonstration purposes only
\usepackage[math]{blindtext}

%for easy quotations: \enquote{text}
\usepackage{csquotes}

%enable margin kerning
\usepackage{microtype}

%tweak \url{...}
\usepackage{url}
%nicer // - solution by http://tex.stackexchange.com/a/98470/9075
\makeatletter
\def\Url@twoslashes{\mathchar`\/\@ifnextchar/{\kern-.2em}{}}
\g@addto@macro\UrlSpecials{\do\/{\Url@twoslashes}}
\makeatother
\urlstyle{same}
%improve wrapping of URLs - hint by http://tex.stackexchange.com/a/10419/9075
\makeatletter
\g@addto@macro{\UrlBreaks}{\UrlOrds}
\makeatother

%diagonal lines in a table - http://tex.stackexchange.com/questions/17745/diagonal-lines-in-table-cell
%slashbox is not available in texlive (due to licensing) and also gives bad results. This, we use diagbox
%\usepackage{diagbox}

%required for pdfcomment later
\usepackage{xcolor}

% new packages BEFORE hyperref
% See also http://tex.stackexchange.com/questions/1863/which-packages-should-be-loaded-after-hyperref-instead-of-before

%enable hyperref without colors and without bookmarks
\usepackage[
%pdfauthor={},
%pdfsubject={},
%pdftitle={},
%pdfkeywords={},
bookmarks=false,
breaklinks=true,
colorlinks=true,
linkcolor=black,
citecolor=black,
urlcolor=black,
%pdfstartpage=19,
pdfpagelayout=SinglePage,
pdfstartview=Fit
]{hyperref}
%enables correct jumping to figures when referencing
\usepackage[all]{hypcap}

%enable nice comments
\usepackage{pdfcomment}
\newcommand{\commentontext}[2]{\colorbox{yellow!60}{#1}\pdfcomment[color={0.234 0.867 0.211},hoffset=-6pt,voffset=10pt,opacity=0.5]{#2}}
\newcommand{\commentatside}[1]{\pdfcomment[color={0.045 0.278 0.643},icon=Note]{#1}}

%compatibality with TODO package
\newcommand{\todo}[1]{\commentatside{#1}}

%enable \cref{...} and \Cref{...} instead of \ref: Type of reference included in the link
\usepackage[capitalise,nameinlink]{cleveref}
%Nice formats for \cref
\crefname{section}{Sect.}{Sect.}
\Crefname{section}{Section}{Sections}

\usepackage{xspace}
%\newcommand{\eg}{e.\,g.\xspace}
%\newcommand{\ie}{i.\,e.\xspace}
\newcommand{\eg}{e.\,g.,\ }
\newcommand{\ie}{i.\,e.,\ }

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\input glyphtounicode.tex
\pdfgentounicode=1

\title{\texttt{timeline}: A Time Series Visualization Platform}
\author{Manuel Haid \and Thomas Mauerhofer \and Matthias W\"olbitsch}
\institute{Knowledge Technologies Institute}

\maketitle

\begin{abstract}
In this paper a web-based visualization platform for time series data is proposed. 
It is not only able to represent static temporal data and its properties, but also data from live sources, such as sensors. 
Furthermore, it allows the visualization of the output of time series prediction methods.
The main aspects of this paper are the overall design, the use cases, and the outlook for possible enhancements of the application.
\end{abstract}

\keywords{Time Series, Visualization, Forecasting}


\section{Introduction}\label{sec:intro}

In today's society data plays a import role in many different ways.
For instance, businesses are using large amount of data to predict consumer behavior to satisfy their demand, or rely on it for operations entirely.
Often time plays a essential role in these real-world data sets and its applications. 
The following list contains three representative examples in no particular order:

\begin{enumerate}
 \item The consumption of electricity does not only depend on the time of the day, but also on the day of the week and other seasonal effects.
 It is important to model the future consumption to avoid failures of large portions or the complete power grid.
 
 \item In the area of weather forecasting time is of the essence. 
 Many applications (\eg shipping) require precise and accurate forecasts to operate on minimal risk.
 
 \item In the finance market many decisions are made within small time spans and are based on the prediction of complex models.
 Incorrect or late data can lead to significant financial losses.
\end{enumerate}


This kind of data set with an temporal importance is usually referred to as time series (\ie two- or higher-dimensional data with time as one dimension). 
A more formal definition \cite{Cortez2012} of a time series \(\{Y\}_t\) is a time ordered collection of observations \((y_1, y_2, \ldots, y_n)\).
This implies two trivial consequences. 
First, the samples in the time series are ordered, and second, previous observations may influence future values but never the other way around.
A element of the time series, recorded at time or period \(t\), denoted as \(y_t\), can either be a scalar value or a vector.
Time series of scalars are denoted as \emph{univariate} times series, whereas a time series of higher dimensional data is called a \emph{multivariate} time series.
For this project we only focused on univariate time series data and refer to to them simply as time series in the context of this paper.

When dealing with time series, usually one of the first steps in the analysis process is the visualization of the data.
The graphical representation can already give some great insights in properties and characteristics of the data.
For example, a simple visual inspection can show patterns, trends, and seasonal effects without the use of advanced statistical methods. 
These properties are important since they have to be considered in the modeling process.
One example for a statistical forecasting model, that requires knowledge of the seasonal and stationary properties of a data set, is the Box--Jenkins \cite{Box1976} model.

The goal of our project is it to create a web-based platform that allows the user to perform this initial visual inspection of the time series in a convenient but sophisticated way.
This includes, of course, the possibility to create simple time series plots (\ie visualizations that plot the data against the time) but also more advanced plots such as the auto-correlation function (ACF) plot.
Another goal is the support of a quick and responsive visualization of forecasts on the a data set. 
This means that is should be possible to quickly inspect the deviation of the prediction from the actual test data including a confidence band.

The rest of the paper is structured as follows. 
\Cref{sec:solution} contains a detailed description of our platform, used algorithms, and overall design.
\Cref{sec:conclusion} contains the conclusion of the project and a discussion of possible future work and improvements.


\section{Solution}\label{sec:solution}

The first step of our design process was the task to decide what types of data sets should be supported by our web-based platform.
We decided that the following types are sufficient for the most common time series analysis tasks:

\begin{enumerate}
 \item A simple time series data set. This consist mainly of a time indexed collection of scalar data points and meta data.
 The meta data is mostly made up of some descriptive information (\ie the name of the data set and a description) and some other details about the data which can be directly derived from it (\eg the number of samples, the period,\ldots).

 \item A specialized version of the simple time series data set were the data is not static but can be updated.
 We denote this type of data set as live time series data set.
 The meta data of the set is basically the same as for the simple time series data set, however, it provides special methods that allows the appending of new data samples at the end of the time series.
 This type of data set is especially useful when dealing with data from live sources (\eg sensors). 
 
 \item A data set which can be used to investigate time series forecasts.
 This object contains the same descriptive meta information as the simple time series data set as well, however, it differs in the actual data it can hold.
 It basically separates a time series into multiple partitions. 
 First, the training data that was used to train the forecasting algorithm and perhaps a time stamp which indices what portion of the training data was used as validation set to determine the performance during the training.
 Furthermore, the prediction (\ie the forecasted time series) is the second part of the data set.
 Optionally, there is should be the possibility to include the test data (\ie the actual values that should be predicted).
\end{enumerate}

After the types of the data sets were fixed, one of the most important design decisions for the project had to be made. 
It was how the \texttt{timeline} platform should be used by the users.
Our first idea was that the platform should be a standalone application.
However, in our opinion, this causes some major usability and implementation issues.
First, there is no nice and easy way to import the three different types data sets at the startup time from files.
It would be very hard to specify a data format that can be utilized by all three data set types.
For example, most of the real-world data sets are stored in the form form of \texttt{.csv} files.
These typically do not allow the storage of additional meta information, at least not without special parsing rules.
Furthermore, the live data sets would require a description of the live data source (\eg a socket) in some way and the forecasting data sets would either require multiple data files (\ie one for the training set, test set, and the prediction) or one file with multiple disjoint sections.

Another possibility for the data import in the standalone application use case would be the possibility to import the data using a dialog in the web-interface.
However, since data sets can be quite large (\ie multiple thousand samples), the upload time could be substantive. 
Moreover, since it was not planned to support persistent storage of the data sets in a rational or document-based database (at least not for the first release), the usability of the platform would suffer due to repeated re-uploads of the data sets. 

Therefore, we decided that the best way to use \texttt{timeline} would be as library. 
This allows the user a much more flexible usage of the platform.
We anticipate more or less the following workflow with \texttt{timeline} and designed the application such that it can be used in that way:

\begin{enumerate}
 \item The user works on a time series analysis or time series forecasting problem using Python or a Jupyter notebook.

 \item The user wants to visualize some aspects of his or her work and imports the \texttt{timeline} library.

 \item He or she creates one or more \texttt{timeline} data set objects that corresponds to the problem he or she is working on and registers it within the library.
 
 \item In the last step he or she can start the \texttt{timeline} web-service on a specific port and can visit the web-interface to view all available visualizations and other information.
\end{enumerate}

The usage of the platform as library also allows a simpler integration of live data sources by simply wrapping the data stream into a class that implements all required live data set methods and the possibility to simply include data sets from other web resources (\eg from a website that publishes stock market data).
Altogether we think that this design choice supports a more natural and quicker workflow with the platform.

Additionally, there are also some example data sets in the library available.
It is possible to generate random data sets with 1000 data points that are sampled from a normal distribution with a random mean in the set \(\{0,1,\ldots,10\}\) and a random standard deviation in the range \([0,2]\).
Furthermore, there is a internet traffic data set from the Time Series Data Library \cite{TSDL} available.
There is a live data set that generates one new sample per second from a normal distribution with some random mean and standard deviation in the same ranges as before.
And there is a simple forecasting data set available which is also based on the internet traffic data set.

The visualization primitives that can be generated by the platform are the following:

\begin{enumerate}
 \item A simple time series plot, which plots the observations (i.e. the data points) against the time of the observations.
 It is possible to filter the time series in a certain time span and include a rolling mean and rolling standard deviation into this plot.
 This can be used to determine whether or not the time series is stationary \cite{Nason2006}.
 
 \item A extended version of the simple time series plot that allows the plotting of multiple time series plots in one figure to compare them directly.
 
 \item A extended version of the simple time series plot that works in the conjunction with live data sets such that it can be updated dynamically. 
 
 \item A autocorrelation plot \cite{Box1976}, also known as autocorrelation function (ACF) plot, which is a statistical tool to proof seasonal effects in the data. 
 
 \item A forecast evaluation plot, that can be used to inspect the performance of a time series prediction method. 
 It is a extended version of the simple time series plot as well, which shows the multiple parts of the forecast data set in one plot. 
\end{enumerate}

The back-end was implemented in Python using Flask \cite{Flask} as web-framework to render the user interface, deliver data using the API, and provide a small web-server such that the application can be executed.
To store the time series data in the back-end the data analysis library Pandas \cite{McKinney2010} was used. 
The application user interface uses the responsive Bootstrap \cite{Bootstrap} front-end framework and the JavaScript visualization library MetricsGraphics.js \cite{MetricsGraphics} to render the visualization primitives. 


\section{Conclusion and Outlook}\label{sec:conclusion}

Like in most other projects, there is a lot room for potential improvements and possible future work.
One constraint, due to the implementation of the framework, is that it only can handle dates and time stamps in a resolution of seconds.
This is caused by the fact that all date and time related parameters are encoded using the UNIX time stamp (\ie the number of seconds since midnight January 1, 1970 UTC) before they are sent from the front-end to the back-end and vice versa.
This is required since dates are often part of URLs, for example, in API requests.
An implication of this is, of course, that it is only possible to handle time series data within a resolution of one second (\eg the period between two samples must be at least one second) in the \texttt{timeline} platform.
This could be problematic, especially for real-time applications, where events usually happen in the range of milliseconds.
However, there are potential solutions for this issue.
For example, one option would be to encode dates as milliseconds since January 1, 1970 or a more general, and probable better, solution would be the usage of a well-defined date time format that allows the reliable parsing of dates from strings, which could be transmitted instead of the UINIX time stamp integers.

Another possibility for future work would be the creation of a Python package that can be uploaded to PyPI \cite{PyPI}, the Python package index.
This would require to write a installer using the Python \texttt{setuptools} module. 
Furthermore, the number of available visualizations is quite small at the time, and the existing plots could be more interactive (\eg brushing).
There are plenty of other plots that could be integrated into the platform, for example, seasonality plots.
However, not only additional visualizations could be added to the platform, but also algorithms and statistical tests that allow further examination of the data sets (\eg implementation of the Dickey--Fuller test \cite{Dickey1979}).

In conclusion we think that the \texttt{timeline} visualization platform could be a valuable tool when doing time series analysis.
It could easily integrated in existing workflows and is modular structured to allow enhancements. 
There is room for potential improvements, but the first version of this application lays a solid foundation for future use cases. 

\bibliographystyle{splncs03}
\bibliography{paper}

\end{document}
